# ğŸš€ Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„Ø©

## Sahool Field Suite Platform - Improvement Roadmap

---

## ğŸ“Š Ù…Ù„Ø®Øµ ØªÙ†ÙÙŠØ°ÙŠ

Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ ØªÙ… ØªØ­Ø¯ÙŠØ¯ **47 ÙØ±ØµØ© ØªØ­Ø³ÙŠÙ†** Ù…ÙˆØ²Ø¹Ø© Ø¹Ù„Ù‰:

| Ø§Ù„ÙØ¦Ø© | Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø§Øª | Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© |
|-------|---------------|----------|
| ğŸ”´ Ø§Ù„Ø£Ù…Ø§Ù† | 13 | Ø­Ø±Ø¬Ø© |
| ğŸŸ  Ø§Ù„Ø£Ø¯Ø§Ø¡ | 12 | Ø¹Ø§Ù„ÙŠØ© |
| ğŸŸ¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª | 6 | Ø¹Ø§Ù„ÙŠØ© |
| ğŸ”µ Ø§Ù„Ù…ÙŠØ²Ø§Øª | 10 | Ù…ØªÙˆØ³Ø·Ø© |
| ğŸŸ¢ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© | 6 | Ù…ØªÙˆØ³Ø·Ø© |

---

## ğŸ”´ Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† (Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù‚ØµÙˆÙ‰)

### 1. ØªÙ†ÙÙŠØ° Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© JWT

```python
# Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ØµØ§Ø¯Ù‚Ø©
# Ø§Ù„Ù…Ù‚ØªØ±Ø­: JWT + OAuth2

from fastapi.security import HTTPBearer, OAuth2PasswordBearer
from jose import jwt, JWTError
from passlib.context import CryptContext

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
SECRET_KEY = os.getenv("JWT_SECRET_KEY")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

def create_access_token(data: dict) -> str:
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

async def get_current_user(token: str = Depends(oauth2_scheme)):
    credentials_exception = HTTPException(
        status_code=401,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    return user_id
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
- âœ… Ø­Ù…Ø§ÙŠØ© Ø¬Ù…ÙŠØ¹ Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
- âœ… ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØ§Ù„Ø¬Ù„Ø³Ø§Øª
- âœ… ÙØµÙ„ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙˆØµÙˆÙ„

---

### 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©

```python
# Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ­Ù‚Ù‚
# Ø§Ù„Ù…Ù‚ØªØ±Ø­:

from fastapi import UploadFile, HTTPException
import magic  # python-magic Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù

class FileValidator:
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    ALLOWED_EXTENSIONS = {".tif", ".tiff", ".jp2"}
    ALLOWED_MIMES = {"image/tiff", "image/jp2"}

    @classmethod
    async def validate(cls, file: UploadFile) -> bool:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…
        content = await file.read()
        if len(content) > cls.MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø£ÙƒØ¨Ø± Ù…Ù† {cls.MAX_FILE_SIZE // (1024*1024)}MB"
            )

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ÙˆØ¹
        mime_type = magic.from_buffer(content[:2048], mime=True)
        if mime_type not in cls.ALLOWED_MIMES:
            raise HTTPException(
                status_code=415,
                detail=f"Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {mime_type}"
            )

        # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ù„Ù„Ø¨Ø¯Ø§ÙŠØ©
        await file.seek(0)
        return True

# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
@router.post("/upload-bands")
async def upload_bands(
    red_band: UploadFile,
    nir_band: UploadFile
):
    await FileValidator.validate(red_band)
    await FileValidator.validate(nir_band)
    # ... Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
- âœ… Ù…Ù†Ø¹ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø¶Ø§Ø±Ø©
- âœ… Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ø³ØªÙ†Ø²Ø§Ù Ø§Ù„Ù‚Ø±Øµ
- âœ… Ø¶Ù…Ø§Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

---

### 3. ØªÙ‚ÙŠÙŠØ¯ CORS

```python
# Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ:
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # âš ï¸ Ø®Ø·ÙŠØ±!
)

# Ø§Ù„Ù…Ù‚ØªØ±Ø­:
ALLOWED_ORIGINS = [
    "https://sahool.app",
    "https://admin.sahool.app",
    "http://localhost:5173",  # Ù„Ù„ØªØ·ÙˆÙŠØ± ÙÙ‚Ø·
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["Authorization", "Content-Type"],
)
```

---

### 4. ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª (Rate Limiting)

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@router.post("/analyze-field")
@limiter.limit("10/minute")  # 10 Ø·Ù„Ø¨Ø§Øª/Ø¯Ù‚ÙŠÙ‚Ø©
async def analyze_field(request: Request, ...):
    ...

@router.post("/ndvi-detect")
@limiter.limit("5/minute")  # Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø«Ù‚ÙŠÙ„Ø©
async def ndvi_detect(request: Request, ...):
    ...
```

---

### 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©

```python
# Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ:
try:
    # ÙƒÙˆØ¯
except:  # âš ï¸ ÙŠÙ„ØªÙ‚Ø· ÙƒÙ„ Ø´ÙŠØ¡!
    continue

# Ø§Ù„Ù…Ù‚ØªØ±Ø­:
from shapely.errors import GEOSException
from rasterio.errors import RasterioIOError

try:
    geom = wkt.loads(field.geom_wkt)
    ndvi_data = rasterio.open(raster_path)
except GEOSException as e:
    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©: {e}")
    raise HTTPException(400, f"Ù‡Ù†Ø¯Ø³Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©: {str(e)}")
except RasterioIOError as e:
    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
    raise HTTPException(400, f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
except Exception as e:
    logger.exception("Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹")
    raise HTTPException(500, "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ")
```

---

## ğŸŸ  Ù…Ù‚ØªØ±Ø­Ø§Øª ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡

### 6. ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Redis

```python
# Ø¥Ø¹Ø¯Ø§Ø¯ Redis
import aioredis
from functools import wraps

redis = aioredis.from_url("redis://localhost:6379")

def cache(ttl: int = 300):
    """Ù…ÙØ²Ø®Ø±Ù Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ ÙØ±ÙŠØ¯
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"

            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
            cached = await redis.get(cache_key)
            if cached:
                return json.loads(cached)

            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø©
            result = await func(*args, **kwargs)

            # ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            await redis.setex(cache_key, ttl, json.dumps(result))
            return result
        return wrapper
    return decorator

# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
@cache(ttl=600)  # 10 Ø¯Ù‚Ø§Ø¦Ù‚
async def get_field_data(field_id: str):
    return await db.query(Field).filter(Field.id == field_id).first()

@cache(ttl=3600)  # Ø³Ø§Ø¹Ø©
async def get_weather_data(lat: float, lon: float):
    return await weather_api.fetch(lat, lon)
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
```
Ù‚Ø¨Ù„: 200ms (database query)
Ø¨Ø¹Ø¯: 5ms (cache hit)
ØªØ­Ø³ÙŠÙ†: 40x Ø£Ø³Ø±Ø¹
Ù†Ø³Ø¨Ø© Cache Hit Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: 80%+
```

---

### 7. SQLAlchemy ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†

```python
# Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: Ù…ØªØ²Ø§Ù…Ù†
from sqlalchemy import create_engine
engine = create_engine(DATABASE_URL)

# Ø§Ù„Ù…Ù‚ØªØ±Ø­: ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

# ØªØºÙŠÙŠØ± URL Ù„Ù„Ù€ async
ASYNC_DATABASE_URL = DATABASE_URL.replace(
    "postgresql://", "postgresql+asyncpg://"
)

async_engine = create_async_engine(ASYNC_DATABASE_URL, echo=True)
AsyncSessionLocal = sessionmaker(
    async_engine, class_=AsyncSession, expire_on_commit=False
)

async def get_db():
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise

# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
@router.get("/fields")
async def get_fields(db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Field))
    return result.scalars().all()
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
```
Ù‚Ø¨Ù„: Ø·Ù„Ø¨ ÙˆØ§Ø­Ø¯ ÙŠØ­Ø¬Ø² thread
Ø¨Ø¹Ø¯: Ø¢Ù„Ø§Ù Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
ØªØ­Ø³ÙŠÙ† Throughput: 5-10x
```

---

### 8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø¨Ø§Ù„Ù‚Ø·Ø¹ (Chunked Processing)

```python
import numpy as np
from rasterio.windows import Window
from concurrent.futures import ThreadPoolExecutor

class OptimizedNDVIProcessor:
    CHUNK_SIZE = 1024  # Ø¨ÙƒØ³Ù„
    MAX_WORKERS = 4

    @classmethod
    async def compute_ndvi_chunked(cls, red_path: str, nir_path: str):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© NDVI Ø¨Ø§Ù„Ù‚Ø·Ø¹ Ù„Ù„ØµÙˆØ± Ø§Ù„ÙƒØ¨ÙŠØ±Ø©"""

        with rasterio.open(red_path) as red_src, \
             rasterio.open(nir_path) as nir_src:

            height, width = red_src.height, red_src.width
            ndvi_result = np.zeros((height, width), dtype=np.float32)

            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ù„Ù‚Ø·Ø¹
            windows = []
            for i in range(0, height, cls.CHUNK_SIZE):
                for j in range(0, width, cls.CHUNK_SIZE):
                    w = Window(
                        j, i,
                        min(cls.CHUNK_SIZE, width - j),
                        min(cls.CHUNK_SIZE, height - i)
                    )
                    windows.append(w)

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ©
            with ThreadPoolExecutor(max_workers=cls.MAX_WORKERS) as executor:
                futures = []
                for window in windows:
                    future = executor.submit(
                        cls._process_chunk,
                        red_src, nir_src, window
                    )
                    futures.append((window, future))

                for window, future in futures:
                    chunk_ndvi = future.result()
                    ndvi_result[
                        window.row_off:window.row_off + window.height,
                        window.col_off:window.col_off + window.width
                    ] = chunk_ndvi

            return ndvi_result

    @staticmethod
    def _process_chunk(red_src, nir_src, window):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø·Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©"""
        red = red_src.read(1, window=window).astype(np.float32)
        nir = nir_src.read(1, window=window).astype(np.float32)

        with np.errstate(divide='ignore', invalid='ignore'):
            ndvi = (nir - red) / (nir + red)
            ndvi = np.nan_to_num(ndvi, nan=0, posinf=1, neginf=-1)

        return ndvi
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
```
ØµÙˆØ±Ø© 10000x10000 Ø¨ÙƒØ³Ù„:
Ù‚Ø¨Ù„: 45 Ø«Ø§Ù†ÙŠØ© (Ø°Ø§ÙƒØ±Ø©: 2GB)
Ø¨Ø¹Ø¯: 12 Ø«Ø§Ù†ÙŠØ© (Ø°Ø§ÙƒØ±Ø©: 256MB)
ØªØ­Ø³ÙŠÙ†: 4x Ø£Ø³Ø±Ø¹ØŒ 8x Ø£Ù‚Ù„ Ø°Ø§ÙƒØ±Ø©
```

---

### 9. ÙÙ‡Ø§Ø±Ø³ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

```python
# Ø¥Ø¶Ø§ÙØ© ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

from sqlalchemy import Index

class Field(Base):
    __tablename__ = "fields"

    id = Column(UUID, primary_key=True)
    tenant_id = Column(UUID, nullable=False)
    name = Column(String(255))
    created_at = Column(DateTime)

    # ÙÙ‡Ø§Ø±Ø³ Ù…Ø±ÙƒØ¨Ø©
    __table_args__ = (
        Index('idx_field_tenant', 'tenant_id'),
        Index('idx_field_tenant_created', 'tenant_id', 'created_at'),
        Index('idx_field_name_search', 'name', postgresql_using='gin',
              postgresql_ops={'name': 'gin_trgm_ops'}),  # Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ
    )

class Recommendation(Base):
    __tablename__ = "recommendations"

    __table_args__ = (
        Index('idx_rec_session', 'session_id'),
        Index('idx_rec_field_status', 'field_id', 'status'),
        Index('idx_rec_priority_created', 'priority', 'created_at'),
    )
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
```
Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¯ÙˆÙ† ÙÙ‡Ø±Ø³: 500ms (full scan)
Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ø¹ ÙÙ‡Ø±Ø³: 5ms (index seek)
ØªØ­Ø³ÙŠÙ†: 100x
```

---

### 10. Ø¶ØºØ· Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª API

```python
from fastapi.middleware.gzip import GZIPMiddleware
from starlette.middleware.base import BaseHTTPMiddleware

# Ø¶ØºØ· GZIP Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
app.add_middleware(GZIPMiddleware, minimum_size=1000)

# ØªØ¨Ø³ÙŠØ· GeoJSON Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª
class GeoJSONSimplifier:
    @staticmethod
    def simplify_geometry(geojson: dict, tolerance: float = 0.0001):
        """ØªØ¨Ø³ÙŠØ· Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…"""
        from shapely.geometry import shape
        from shapely.ops import transform

        geom = shape(geojson)
        simplified = geom.simplify(tolerance, preserve_topology=True)
        return simplified.__geo_interface__

# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
@router.get("/zones/{field_id}")
async def get_zones(field_id: str, simplify: bool = True):
    zones = await get_field_zones(field_id)

    if simplify:
        for zone in zones:
            zone["geometry"] = GeoJSONSimplifier.simplify_geometry(
                zone["geometry"]
            )

    return zones
```

**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
```
Ø­Ø¬Ù… Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:
Ù‚Ø¨Ù„: 500KB (GeoJSON ÙƒØ§Ù…Ù„)
Ø¨Ø¹Ø¯: 50KB (Ù…Ø¨Ø³Ø· + Ù…Ø¶ØºÙˆØ·)
ØªØ­Ø³ÙŠÙ†: 90% ØªÙˆÙÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ±Ø¯Ø¯ÙŠ
```

---

## ğŸŸ¡ Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª

### 11. Ø²ÙŠØ§Ø¯Ø© ØªØºØ·ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª

```python
# tests/test_ndvi_service.py

import pytest
from unittest.mock import Mock, patch, AsyncMock
import numpy as np

class TestNDVIService:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø®Ø¯Ù…Ø© NDVI"""

    @pytest.fixture
    def mock_raster_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±"""
        return {
            "red": np.array([[100, 150], [200, 250]], dtype=np.float32),
            "nir": np.array([[200, 300], [400, 500]], dtype=np.float32),
            "expected_ndvi": np.array([[0.333, 0.333], [0.333, 0.333]], dtype=np.float32)
        }

    def test_ndvi_calculation_normal(self, mock_raster_data):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø³Ø§Ø¨ NDVI Ø§Ù„Ø¹Ø§Ø¯ÙŠ"""
        red = mock_raster_data["red"]
        nir = mock_raster_data["nir"]

        ndvi = (nir - red) / (nir + red)

        assert ndvi.shape == (2, 2)
        assert -1 <= ndvi.min() <= 1
        assert -1 <= ndvi.max() <= 1

    def test_ndvi_division_by_zero(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±"""
        red = np.array([[0, 100]], dtype=np.float32)
        nir = np.array([[0, 200]], dtype=np.float32)

        with np.errstate(divide='ignore', invalid='ignore'):
            ndvi = (nir - red) / (nir + red)
            ndvi = np.nan_to_num(ndvi, nan=0)

        assert ndvi[0, 0] == 0  # 0/0 = nan -> 0

    def test_ndvi_negative_values(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø© (Ù…Ø§Ø¡)"""
        red = np.array([[200]], dtype=np.float32)
        nir = np.array([[100]], dtype=np.float32)

        ndvi = (nir - red) / (nir + red)

        assert ndvi[0, 0] < 0  # Ø§Ù„Ù…Ø§Ø¡ Ù„Ù‡ NDVI Ø³Ø§Ù„Ø¨

    @pytest.mark.parametrize("threshold,expected_zones", [
        (0.3, 3),  # Ø¹ØªØ¨Ø© Ù…Ù†Ø®ÙØ¶Ø© = Ù…Ù†Ø§Ø·Ù‚ Ø£ÙƒØ«Ø±
        (0.5, 2),  # Ø¹ØªØ¨Ø© Ù…ØªÙˆØ³Ø·Ø©
        (0.7, 1),  # Ø¹ØªØ¨Ø© Ø¹Ø§Ù„ÙŠØ© = Ù…Ù†Ø§Ø·Ù‚ Ø£Ù‚Ù„
    ])
    def test_zone_detection_thresholds(self, threshold, expected_zones):
        """Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø¨Ø¹ØªØ¨Ø§Øª Ù…Ø®ØªÙ„ÙØ©"""
        # ... ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±


class TestAdvisorRulesEngine:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"""

    @pytest.fixture
    def rules_engine(self):
        return RulesEngine()

    def test_low_ndvi_triggers_irrigation(self, rules_engine):
        """NDVI Ù…Ù†Ø®ÙØ¶ ÙŠÙØ·Ù„Ù‚ ØªÙˆØµÙŠØ© Ø±ÙŠ"""
        context = {
            "ndvi": {"mean": 0.25, "std": 0.1},
            "weather": {"temperature": 30}
        }

        recommendations = rules_engine.evaluate(context)

        irrigation_recs = [r for r in recommendations if r["category"] == "irrigation"]
        assert len(irrigation_recs) > 0
        assert irrigation_recs[0]["priority"] in ["high", "critical"]

    def test_high_temp_triggers_alert(self, rules_engine):
        """Ø­Ø±Ø§Ø±Ø© Ø¹Ø§Ù„ÙŠØ© ØªÙØ·Ù„Ù‚ ØªÙ†Ø¨ÙŠÙ‡"""
        context = {
            "ndvi": {"mean": 0.6},
            "weather": {"temperature": 42}
        }

        recommendations = rules_engine.evaluate(context)

        assert any(r["priority"] == "high" for r in recommendations)


class TestAPIEndpoints:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ©"""

    @pytest.fixture
    def client(self):
        from fastapi.testclient import TestClient
        return TestClient(app)

    def test_analyze_field_success(self, client):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø­Ù‚Ù„ Ø¨Ù†Ø¬Ø§Ø­"""
        response = client.post("/api/advisor/analyze-field", json={
            "field_id": "test-field-001",
            "ndvi_data": {"mean": 0.6, "std": 0.1}
        })

        assert response.status_code == 200
        data = response.json()
        assert "recommendations" in data
        assert "alerts" in data
        assert "overall_health_score" in data

    def test_analyze_field_invalid_input(self, client):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¯Ø®Ø§Ù„ ØºÙŠØ± ØµØ§Ù„Ø­"""
        response = client.post("/api/advisor/analyze-field", json={
            "field_id": ""  # ÙØ§Ø±Øº
        })

        assert response.status_code == 422  # Validation Error

    def test_health_check(self, client):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù‚Ø·Ø© Ø§Ù„ØµØ­Ø©"""
        response = client.get("/health")

        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
```

---

### 12. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„ (Load Testing)

```python
# tests/load/locustfile.py

from locust import HttpUser, task, between

class FieldAnalysisUser(HttpUser):
    """Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„"""
    wait_time = between(1, 3)

    @task(3)
    def analyze_field(self):
        """ØªØ­Ù„ÙŠÙ„ Ø­Ù‚Ù„ - Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Ù‹"""
        self.client.post("/api/advisor/analyze-field", json={
            "field_id": f"field-{self.user_id}",
            "ndvi_data": {"mean": 0.55, "std": 0.12}
        })

    @task(2)
    def get_recommendations(self):
        """Ø¬Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        self.client.get("/api/advisor/recommendations?field_id=field-001")

    @task(1)
    def health_check(self):
        """ÙØ­Øµ Ø§Ù„ØµØ­Ø©"""
        self.client.get("/health")

# Ø§Ù„ØªØ´ØºÙŠÙ„:
# locust -f tests/load/locustfile.py --host=http://localhost:8000
```

**Ø§Ù„Ø£Ù‡Ø¯Ø§Ù:**
```
Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†ÙˆÙ†: 100
Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª: 500/Ø«Ø§Ù†ÙŠØ©
Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© p95: <200ms
Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£: <0.1%
```

---

## ğŸ”µ Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

### 13. WebSocket Ù„Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„ÙÙˆØ±ÙŠØ©

```python
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict, Set

class ConnectionManager:
    """Ø¥Ø¯Ø§Ø±Ø© Ø§ØªØµØ§Ù„Ø§Øª WebSocket"""

    def __init__(self):
        self.active_connections: Dict[str, Set[WebSocket]] = {}

    async def connect(self, websocket: WebSocket, field_id: str):
        await websocket.accept()
        if field_id not in self.active_connections:
            self.active_connections[field_id] = set()
        self.active_connections[field_id].add(websocket)

    def disconnect(self, websocket: WebSocket, field_id: str):
        self.active_connections[field_id].discard(websocket)

    async def broadcast_to_field(self, field_id: str, message: dict):
        """Ø¨Ø« Ø±Ø³Ø§Ù„Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØµÙ„ÙŠÙ† Ø¨Ø­Ù‚Ù„ Ù…Ø¹ÙŠÙ†"""
        if field_id in self.active_connections:
            for connection in self.active_connections[field_id]:
                await connection.send_json(message)

manager = ConnectionManager()

@app.websocket("/ws/field/{field_id}")
async def websocket_endpoint(websocket: WebSocket, field_id: str):
    await manager.connect(websocket, field_id)
    try:
        while True:
            data = await websocket.receive_json()

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ÙˆØ§Ø±Ø¯Ø©
            if data.get("type") == "request_analysis":
                # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª
                await manager.broadcast_to_field(field_id, {
                    "type": "analysis_started",
                    "progress": 0
                })

                # ... ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¯ÙˆØ±ÙŠØ©

                await manager.broadcast_to_field(field_id, {
                    "type": "analysis_complete",
                    "progress": 100,
                    "results": {...}
                })

    except WebSocketDisconnect:
        manager.disconnect(websocket, field_id)
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- âœ… ØªØ­Ø¯ÙŠØ«Ø§Øª ÙÙˆØ±ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„
- âœ… ØªÙ‚Ù„ÙŠÙ„ polling
- âœ… ØªØ¬Ø±Ø¨Ø© Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙØ¶Ù„

---

### 14. Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª

```python
from enum import Enum
from pydantic import BaseModel
from typing import Optional
import aiosmtplib
from twilio.rest import Client

class NotificationType(str, Enum):
    EMAIL = "email"
    SMS = "sms"
    PUSH = "push"
    IN_APP = "in_app"

class NotificationService:
    """Ø®Ø¯Ù…Ø© Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""

    def __init__(self):
        self.email_client = aiosmtplib.SMTP(...)
        self.sms_client = Client(TWILIO_SID, TWILIO_TOKEN)
        self.push_client = firebase_admin.messaging

    async def send(
        self,
        user_id: str,
        title: str,
        message: str,
        notification_type: NotificationType,
        priority: str = "normal",
        data: Optional[dict] = None
    ):
        """Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø±"""

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±
        notification = await self._log_notification(
            user_id, title, message, notification_type
        )

        if notification_type == NotificationType.EMAIL:
            await self._send_email(user_id, title, message)
        elif notification_type == NotificationType.SMS:
            await self._send_sms(user_id, message)
        elif notification_type == NotificationType.PUSH:
            await self._send_push(user_id, title, message, data)
        elif notification_type == NotificationType.IN_APP:
            await self._send_in_app(user_id, title, message)

        return notification

    async def send_alert(self, alert: Alert):
        """Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø²Ø±Ø§Ø¹ÙŠ"""
        user_prefs = await self._get_user_preferences(alert.user_id)

        # ØªØ­Ø¯ÙŠØ¯ Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        channels = []
        if alert.type == "critical":
            channels = [NotificationType.SMS, NotificationType.PUSH, NotificationType.EMAIL]
        elif alert.type == "warning":
            channels = [NotificationType.PUSH, NotificationType.EMAIL]
        else:
            channels = [NotificationType.IN_APP]

        for channel in channels:
            if user_prefs.get(channel.value, True):
                await self.send(
                    user_id=alert.user_id,
                    title=alert.title,
                    message=alert.message,
                    notification_type=channel,
                    priority=alert.type
                )
```

---

### 15. ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

```python
import csv
import io
from openpyxl import Workbook
from fastapi.responses import StreamingResponse

class ExportService:
    """Ø®Ø¯Ù…Ø© ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""

    @staticmethod
    async def export_recommendations_csv(
        field_id: str,
        start_date: datetime,
        end_date: datetime
    ) -> StreamingResponse:
        """ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙˆØµÙŠØ§Øª ÙƒÙ€ CSV"""

        recommendations = await get_recommendations(field_id, start_date, end_date)

        output = io.StringIO()
        writer = csv.DictWriter(output, fieldnames=[
            "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„ÙØ¦Ø©", "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©", "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†", "Ø§Ù„ÙˆØµÙ", "Ø§Ù„Ø­Ø§Ù„Ø©"
        ])
        writer.writeheader()

        for rec in recommendations:
            writer.writerow({
                "Ø§Ù„ØªØ§Ø±ÙŠØ®": rec.created_at.strftime("%Y-%m-%d"),
                "Ø§Ù„ÙØ¦Ø©": rec.category,
                "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©": rec.priority,
                "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": rec.title,
                "Ø§Ù„ÙˆØµÙ": rec.description,
                "Ø§Ù„Ø­Ø§Ù„Ø©": rec.status
            })

        output.seek(0)
        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=recommendations_{field_id}.csv"
            }
        )

    @staticmethod
    async def export_field_report_pdf(field_id: str) -> bytes:
        """ØªØµØ¯ÙŠØ± ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ù‚Ù„ ÙƒÙ€ PDF"""
        from reportlab.lib import colors
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Table, Paragraph

        # ... Ø¥Ù†Ø´Ø§Ø¡ PDF

    @staticmethod
    async def export_zones_geojson(field_id: str) -> dict:
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ ÙƒÙ€ GeoJSON"""
        zones = await get_field_zones(field_id)

        return {
            "type": "FeatureCollection",
            "features": [
                {
                    "type": "Feature",
                    "geometry": zone.geometry,
                    "properties": {
                        "zone_id": zone.id,
                        "ndvi_mean": zone.ndvi_mean,
                        "health_status": zone.health_status
                    }
                }
                for zone in zones
            ]
        }
```

---

### 16. Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„Ù…Ø¯ÙŠØ±

```typescript
// web/src/pages/AdminDashboard.tsx

import React, { useState, useEffect } from 'react';
import { LineChart, BarChart, PieChart } from 'recharts';

interface SystemMetrics {
  activeUsers: number;
  totalFields: number;
  analysisToday: number;
  avgResponseTime: number;
  errorRate: number;
  cpuUsage: number;
  memoryUsage: number;
}

const AdminDashboard: React.FC = () => {
  const [metrics, setMetrics] = useState<SystemMetrics | null>(null);
  const [alerts, setAlerts] = useState([]);

  useEffect(() => {
    fetchMetrics();
    const interval = setInterval(fetchMetrics, 30000); // ÙƒÙ„ 30 Ø«Ø§Ù†ÙŠØ©
    return () => clearInterval(interval);
  }, []);

  return (
    <div className="admin-dashboard p-6">
      <h1 className="text-2xl font-bold mb-6">Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„Ù†Ø¸Ø§Ù…</h1>

      {/* Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© */}
      <div className="grid grid-cols-4 gap-4 mb-6">
        <MetricCard
          title="Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ù†Ø´Ø·ÙˆÙ†"
          value={metrics?.activeUsers}
          icon="ğŸ‘¥"
        />
        <MetricCard
          title="Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ÙŠÙˆÙ…"
          value={metrics?.analysisToday}
          icon="ğŸ“Š"
        />
        <MetricCard
          title="Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©"
          value={`${metrics?.avgResponseTime}ms`}
          icon="âš¡"
        />
        <MetricCard
          title="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"
          value={`${metrics?.errorRate}%`}
          icon="âš ï¸"
          alert={metrics?.errorRate > 1}
        />
      </div>

      {/* Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© */}
      <div className="grid grid-cols-2 gap-6">
        <div className="bg-white rounded-lg shadow p-4">
          <h3 className="font-semibold mb-4">Ø·Ù„Ø¨Ø§Øª API (Ø¢Ø®Ø± 24 Ø³Ø§Ø¹Ø©)</h3>
          <LineChart data={apiRequestsData} />
        </div>

        <div className="bg-white rounded-lg shadow p-4">
          <h3 className="font-semibold mb-4">ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª</h3>
          <PieChart data={recommendationsData} />
        </div>
      </div>

      {/* Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª */}
      <div className="mt-6 bg-white rounded-lg shadow p-4">
        <h3 className="font-semibold mb-4">ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…</h3>
        <AlertsList alerts={alerts} />
      </div>
    </div>
  );
};
```

---

## ğŸŸ¢ Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ©

### 17. CI/CD Pipeline

```yaml
# .github/workflows/ci-cd.yml

name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgis/postgis:15-3.3
        env:
          POSTGRES_PASSWORD: test
        ports:
          - 5432:5432
      redis:
        image: redis:7
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio

      - name: Run tests
        run: |
          pytest tests/ -v --cov=app --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run linters
        run: |
          pip install ruff black mypy
          ruff check .
          black --check .
          mypy app/

  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Security scan
        run: |
          pip install bandit safety
          bandit -r app/
          safety check

  build:
    needs: [test, lint, security]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Build Docker image
        run: |
          docker build -t sahool/field-advisor:${{ github.sha }} .

      - name: Push to registry
        if: github.ref == 'refs/heads/main'
        run: |
          docker push sahool/field-advisor:${{ github.sha }}

  deploy:
    needs: build
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production
        run: |
          # Kubernetes deployment
          kubectl set image deployment/field-advisor \
            field-advisor=sahool/field-advisor:${{ github.sha }}
```

---

### 18. Kubernetes Deployment

```yaml
# k8s/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: field-advisor
  labels:
    app: field-advisor
spec:
  replicas: 3
  selector:
    matchLabels:
      app: field-advisor
  template:
    metadata:
      labels:
        app: field-advisor
    spec:
      containers:
        - name: field-advisor
          image: sahool/field-advisor:latest
          ports:
            - containerPort: 8001
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8001
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 8001
            initialDelaySeconds: 5
            periodSeconds: 5
          env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: field-advisor-secrets
                  key: database-url
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: field-advisor-secrets
                  key: redis-url

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: field-advisor-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: field-advisor
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
```

---

### 19. Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª

```yaml
# prometheus/alerts.yml

groups:
  - name: field-advisor-alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø·Ø§Ø¡ Ø¹Ø§Ù„ÙŠ ÙÙŠ Field Advisor"
          description: "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ {{ $value | humanizePercentage }} Ø®Ù„Ø§Ù„ Ø¢Ø®Ø± 5 Ø¯Ù‚Ø§Ø¦Ù‚"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¹Ø§Ù„ÙŠ"
          description: "p95 Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© {{ $value | humanizeDuration }}"

      - alert: LowNDVIDetected
        expr: avg(field_ndvi_mean) < 0.3
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "NDVI Ù…Ù†Ø®ÙØ¶ Ù…ÙƒØªØ´Ù"
          description: "Ù…ØªÙˆØ³Ø· NDVI Ù„Ù„Ø­Ù‚ÙˆÙ„ {{ $value }}"

      - alert: DatabaseConnectionFailure
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
```

---

## ğŸ“… Ø®Ø§Ø±Ø·Ø© Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªÙ†ÙÙŠØ°

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø£Ù…Ø§Ù† (Ø£Ø³Ø¨ÙˆØ¹ 1-2)
```
â–¡ ØªÙ†ÙÙŠØ° JWT Authentication
â–¡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
â–¡ ØªÙ‚ÙŠÙŠØ¯ CORS
â–¡ Ø¥Ø¶Ø§ÙØ© Rate Limiting
â–¡ Ø¥ØµÙ„Ø§Ø­ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª
```

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„Ø£Ø¯Ø§Ø¡ (Ø£Ø³Ø¨ÙˆØ¹ 3-4)
```
â–¡ ØªÙ†ÙÙŠØ° Redis Caching
â–¡ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Async SQLAlchemy
â–¡ Ø¥Ø¶Ø§ÙØ© ÙÙ‡Ø§Ø±Ø³ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
â–¡ ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
â–¡ Ø¥Ø¶Ø§ÙØ© Ø¶ØºØ· Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª
```

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø£Ø³Ø¨ÙˆØ¹ 5-6)
```
â–¡ Ø²ÙŠØ§Ø¯Ø© Unit Tests Ø¥Ù„Ù‰ 80%+
â–¡ Ø¥Ø¶Ø§ÙØ© Integration Tests
â–¡ Ø¥Ø¹Ø¯Ø§Ø¯ Load Testing
â–¡ Ø¥Ø¶Ø§ÙØ© Security Tests
```

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ù„Ù…ÙŠØ²Ø§Øª (Ø£Ø³Ø¨ÙˆØ¹ 7-10)
```
â–¡ Ø¥Ø¶Ø§ÙØ© WebSocket
â–¡ ØªÙ†ÙÙŠØ° Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª
â–¡ Ø¥Ø¶Ø§ÙØ© Export Service
â–¡ Ø¥Ù†Ø´Ø§Ø¡ Admin Dashboard
â–¡ Ø¥Ø¶Ø§ÙØ© API Versioning
```

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© (Ø£Ø³Ø¨ÙˆØ¹ 11-12)
```
â–¡ Ø¥Ø¹Ø¯Ø§Ø¯ CI/CD
â–¡ Ø¥Ù†Ø´Ø§Ø¡ Kubernetes manifests
â–¡ ØªÙƒÙˆÙŠÙ† Monitoring
â–¡ Ø¥Ø¹Ø¯Ø§Ø¯ Logging Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ
```

---

## ğŸ“Š Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù†Ø¬Ø§Ø­

| Ø§Ù„Ù…Ø¤Ø´Ø± | Ø§Ù„Ø­Ø§Ù„ÙŠ | Ø§Ù„Ù‡Ø¯Ù |
|--------|--------|-------|
| ØªØºØ·ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª | ~30% | 80%+ |
| Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© p95 | 500ms | <200ms |
| Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ | ~2% | <0.1% |
| Uptime | 95% | 99.9% |
| Cache Hit Rate | 0% | 80%+ |
| Security Score | 40/100 | 90/100 |

---

*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©: 2025-12-02*
*Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: Sahool Field Suite Platform*
*Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 1.0*
