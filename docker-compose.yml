version: "3.9"

services:
  postgres:
    image: postgis/postgis:15-3.4
    container_name: sahool-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: sahool
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - pgdata_sahool:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d sahool"]
      interval: 10s
      timeout: 5s
      retries: 5

  gateway-edge:
    # Replace this with your actual image/build for the gateway
    build:
      context: ./multi-repo/gateway-edge/multi-repo/gateway-edge
    container_name: gateway-edge
    restart: unless-stopped
    ports:
      - "9000:9000"
    depends_on:
      - postgres
    # Optional: if your gateway needs env variables, put them here
    environment:
      DATABASE_URL: postgres://postgres:postgres@postgres:5432/sahool

  # ML Engine Service
  ml-engine:
    build:
      context: ./multi-repo/ml-engine
      dockerfile: Dockerfile
    container_name: sahool-ml-engine
    restart: unless-stopped
    ports:
      - "8010:8010"
    environment:
      # Service Configuration
      SERVICE_NAME: ml-engine
      SERVICE_PORT: 8010

      # ML Model Paths (optional - will use defaults if not set)
      MODEL_PATH: /app/models

      # Database (if needed for storing predictions)
      DATABASE_URL: postgres://postgres:postgres@postgres:5432/sahool

      # Optional: External APIs
      # OPENWEATHER_API_KEY: your_key_here

    volumes:
      # Persist trained models
      - ml_models:/app/models
      # Cache for downloaded models
      - ml_cache:/root/.cache
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8010/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - postgres

  # Agent-AI Service with LangChain
  agent-ai:
    build:
      context: ./multi-repo/agent-ai
      dockerfile: Dockerfile
    container_name: sahool-agent-ai
    restart: unless-stopped
    ports:
      - "8002:8002"
    environment:
      # Service Configuration
      SERVICE_NAME: agent-ai
      SERVICE_PORT: 8002

      # Gateway URL for data fetching
      GATEWAY_URL: http://gateway-edge:9000

      # LLM Provider (optional - falls back to rule-based if not set)
      # LLM_PROVIDER: openai  # Options: openai, anthropic, fallback
      # OPENAI_API_KEY: sk-...
      # ANTHROPIC_API_KEY: sk-ant-...

      # Vector Store
      CHROMA_DB_PATH: /app/data/chroma_db

      # Optional: LangSmith tracing
      # LANGSMITH_API_KEY: ...
      # LANGSMITH_TRACING: true

    volumes:
      # Persist vector database
      - agent_knowledge:/app/data
      # Cache for embeddings models
      - agent_cache:/root/.cache
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - gateway-edge

volumes:
  pgdata_sahool:
  minio_data:
  ml_models:
    driver: local
  ml_cache:
    driver: local
  agent_knowledge:
    driver: local
  agent_cache:
    driver: local
